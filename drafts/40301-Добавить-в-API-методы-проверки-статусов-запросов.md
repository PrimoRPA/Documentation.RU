Статья https://docs.primo-rpa.ru/ru/primo-ai/developer/tutorial

- Не работает ссылка из "[Задачи NLP](https://docs.primo-rpa.ru/primo-ai/developer/tutorial/nlp) — работа с компонентом Задачи NLP: отправка запроса к LLM, получение результата. Раздел в разработке"

Статья https://docs.primo-rpa.ru/ru/primo-ai/developer/tutorial/smart-ocr



Добавить пункт 6:
 
6. Проверка статуса модели

Проверить статус сервера и модели можно методом `GET /inference/smartOCR/status`.
Укажите заголовок modelType с типом используемой модели. Также добавьте текущий токен в заголовок Authorization:.

Пример запроса:

```
GET /inference/smartOCR/status HTTP/1.1
Host: ai-server-endpoint:44392
Accept: application/json
Authorization: •••••
modelType: XXXX
```

В ответе будет JSON со статусом модели и сервера.
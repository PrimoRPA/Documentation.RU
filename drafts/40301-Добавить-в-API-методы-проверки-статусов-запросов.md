### Notes 

Статья https://docs.primo-rpa.ru/ru/primo-ai/developer/tutorial

- Не работает ссылка из "[Задачи NLP](https://docs.primo-rpa.ru/primo-ai/developer/tutorial/nlp) — работа с компонентом Задачи NLP: отправка запроса к LLM, получение результата. Раздел в разработке"

Для NLP нет похоже статьи.  
Для SmartOCR: Статья https://docs.primo-rpa.ru/ru/primo-ai/developer/tutorial/smart-ocr. Текст ниже 


### Добавить пункт 6
 
6. Проверка статуса модели

Проверить статус сервера и модели можно методом `GET /inference/smartOCR/status`:

- Укажите заголовок modelType с типом используемой модели. 
- Добавьте текущий токен в заголовок Authorization.

Пример запроса:

```
GET /inference/smartOCR/status HTTP/1.1
Host: ai-server-endpoint:44392
Accept: application/json
Authorization: •••••
modelType: XXXX
```

В ответе будет JSON со статусом модели и сервера.

